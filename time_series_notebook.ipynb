{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_pollution_timeseries.csv')\n",
    "df = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dew: Dew Point\n",
    "- temp: Temperature\n",
    "- press: Pressure\n",
    "- wnd_spd: Cumulated wind speed\n",
    "- snow: Cumulated hours of snow\n",
    "- rain: Cumulated hours of rain\n",
    "- pollution: 1 (yes) or 0 (no), threshold=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pollution\n",
       "0            947\n",
       "1            878\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[['timestamp', 'pollution']].groupby('timestamp').max()\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            dew  temp   press  wnd_spd  snow  rain\n",
       "timestamp                                         \n",
       "2010-01-02  -16  -4.0  1020.0     1.79     0     0\n",
       "2010-01-02  -15  -4.0  1020.0     2.68     0     0\n",
       "2010-01-02  -11  -5.0  1021.0     3.57     0     0\n",
       "2010-01-02   -7  -5.0  1022.0     5.36     1     0\n",
       "2010-01-02   -7  -5.0  1022.0     6.25     2     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('timestamp')\n",
    "X = df.drop(['pollution', 'hour'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X.index) * 0.8)\n",
    "X_train = X.iloc[:train_size, :]\n",
    "X_test = X.iloc[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lstm = X_train.reshape(int(X_train.shape[0]/24), -1, X_train.shape[1])\t\t# shape: 1460 days (4 years), 24 hours, 7 features\n",
    "y_train_lstm = np.array(y)[:int(X_train_lstm.shape[0])]\n",
    "\n",
    "X_test_lstm = X_test.reshape(int(X_test.shape[0]/24), -1, X_test.shape[1])\t\t\t# shape: 365 days (1 year), 24 hours, 7 features\n",
    "y_test_lstm = np.array(y)[int(X_train_lstm.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 5s 46ms/step - loss: 0.6172 - accuracy: 0.6370 - val_loss: 0.5966 - val_accuracy: 0.6603\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.5382 - accuracy: 0.7212 - val_loss: 0.6348 - val_accuracy: 0.6247\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.5263 - accuracy: 0.7349 - val_loss: 0.5712 - val_accuracy: 0.6795\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.5174 - accuracy: 0.7315 - val_loss: 0.5868 - val_accuracy: 0.6959\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.5261 - accuracy: 0.7301 - val_loss: 0.5573 - val_accuracy: 0.6932\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.5155 - accuracy: 0.7397 - val_loss: 0.5373 - val_accuracy: 0.7425\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.5184 - accuracy: 0.7384 - val_loss: 0.5415 - val_accuracy: 0.7068\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.5117 - accuracy: 0.7500 - val_loss: 0.5744 - val_accuracy: 0.6822\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.5287 - accuracy: 0.7349 - val_loss: 0.5428 - val_accuracy: 0.7178\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4992 - accuracy: 0.7514 - val_loss: 0.5573 - val_accuracy: 0.7342\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.4974 - accuracy: 0.7521 - val_loss: 0.6751 - val_accuracy: 0.6877\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4994 - accuracy: 0.7486 - val_loss: 0.5176 - val_accuracy: 0.7644\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.5089 - accuracy: 0.7486 - val_loss: 0.5149 - val_accuracy: 0.7644\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5061 - accuracy: 0.7479 - val_loss: 0.5587 - val_accuracy: 0.7479\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4902 - accuracy: 0.7616 - val_loss: 0.5744 - val_accuracy: 0.7096\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.5067 - accuracy: 0.7466 - val_loss: 0.5468 - val_accuracy: 0.7315\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4952 - accuracy: 0.7685 - val_loss: 0.5312 - val_accuracy: 0.7479\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.5000 - accuracy: 0.7582 - val_loss: 0.5773 - val_accuracy: 0.7288\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4976 - accuracy: 0.7651 - val_loss: 0.5561 - val_accuracy: 0.7041\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4854 - accuracy: 0.7658 - val_loss: 0.5564 - val_accuracy: 0.6986\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.5033 - accuracy: 0.7555 - val_loss: 0.5464 - val_accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4886 - accuracy: 0.7623 - val_loss: 0.5172 - val_accuracy: 0.7589\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.5096 - accuracy: 0.7521 - val_loss: 0.5436 - val_accuracy: 0.6986\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 0.4819 - accuracy: 0.7658 - val_loss: 0.5281 - val_accuracy: 0.7397\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4931 - accuracy: 0.7534 - val_loss: 0.5337 - val_accuracy: 0.7397\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4775 - accuracy: 0.7671 - val_loss: 0.5232 - val_accuracy: 0.7315\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4767 - accuracy: 0.7726 - val_loss: 0.5458 - val_accuracy: 0.7123\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4864 - accuracy: 0.7664 - val_loss: 0.4809 - val_accuracy: 0.7507\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4847 - accuracy: 0.7568 - val_loss: 0.5150 - val_accuracy: 0.7178\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4878 - accuracy: 0.7678 - val_loss: 0.5251 - val_accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4849 - accuracy: 0.7610 - val_loss: 0.5437 - val_accuracy: 0.7205\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4869 - accuracy: 0.7651 - val_loss: 0.5466 - val_accuracy: 0.7315\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4719 - accuracy: 0.7726 - val_loss: 0.5121 - val_accuracy: 0.7370\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4678 - accuracy: 0.7637 - val_loss: 0.5345 - val_accuracy: 0.7315\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4799 - accuracy: 0.7623 - val_loss: 0.5278 - val_accuracy: 0.7479\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4634 - accuracy: 0.7815 - val_loss: 0.5876 - val_accuracy: 0.6986\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4630 - accuracy: 0.7815 - val_loss: 0.5148 - val_accuracy: 0.7534\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4587 - accuracy: 0.7801 - val_loss: 0.5005 - val_accuracy: 0.7589\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4699 - accuracy: 0.7740 - val_loss: 0.5393 - val_accuracy: 0.7479\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4578 - accuracy: 0.7856 - val_loss: 0.4894 - val_accuracy: 0.7562\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.5277 - val_accuracy: 0.7315\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.4632 - accuracy: 0.7719 - val_loss: 0.5169 - val_accuracy: 0.7644\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4625 - accuracy: 0.7705 - val_loss: 0.5185 - val_accuracy: 0.7479\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4573 - accuracy: 0.7925 - val_loss: 0.5109 - val_accuracy: 0.7616\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.4531 - accuracy: 0.7890 - val_loss: 0.4997 - val_accuracy: 0.7479\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.4592 - accuracy: 0.7774 - val_loss: 0.5141 - val_accuracy: 0.7534\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.4587 - accuracy: 0.7801 - val_loss: 0.5182 - val_accuracy: 0.7233\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4562 - accuracy: 0.7863 - val_loss: 0.5392 - val_accuracy: 0.7370\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4466 - accuracy: 0.7829 - val_loss: 0.5948 - val_accuracy: 0.7342\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4582 - accuracy: 0.7781 - val_loss: 0.5108 - val_accuracy: 0.7425\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4627 - accuracy: 0.7863 - val_loss: 0.5095 - val_accuracy: 0.7562\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4504 - accuracy: 0.7884 - val_loss: 0.4767 - val_accuracy: 0.7671\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4512 - accuracy: 0.7856 - val_loss: 0.5672 - val_accuracy: 0.7260\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.5484 - val_accuracy: 0.7589\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4548 - accuracy: 0.7884 - val_loss: 0.5254 - val_accuracy: 0.7616\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4495 - accuracy: 0.7842 - val_loss: 0.4869 - val_accuracy: 0.7808\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4410 - accuracy: 0.7870 - val_loss: 0.5222 - val_accuracy: 0.7452\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4455 - accuracy: 0.7897 - val_loss: 0.4815 - val_accuracy: 0.7726\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4419 - accuracy: 0.7938 - val_loss: 0.5071 - val_accuracy: 0.7699\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4424 - accuracy: 0.7932 - val_loss: 0.5073 - val_accuracy: 0.7644\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4319 - accuracy: 0.7911 - val_loss: 0.5156 - val_accuracy: 0.7753\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 0.4477 - accuracy: 0.7863 - val_loss: 0.5160 - val_accuracy: 0.7260\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4429 - accuracy: 0.7973 - val_loss: 0.4879 - val_accuracy: 0.7671\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.5053 - val_accuracy: 0.7671\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.4530 - accuracy: 0.7890 - val_loss: 0.5084 - val_accuracy: 0.7671\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 0.4328 - accuracy: 0.7973 - val_loss: 0.5222 - val_accuracy: 0.7644\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 0.4350 - accuracy: 0.7877 - val_loss: 0.5565 - val_accuracy: 0.7370\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4306 - accuracy: 0.7979 - val_loss: 0.5049 - val_accuracy: 0.7726\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4375 - accuracy: 0.7884 - val_loss: 0.5232 - val_accuracy: 0.7808\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4434 - accuracy: 0.7781 - val_loss: 0.4959 - val_accuracy: 0.7616\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4490 - accuracy: 0.7856 - val_loss: 0.5223 - val_accuracy: 0.7671\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4341 - accuracy: 0.7979 - val_loss: 0.5183 - val_accuracy: 0.7452\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4283 - accuracy: 0.7945 - val_loss: 0.5208 - val_accuracy: 0.7507\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4285 - accuracy: 0.7904 - val_loss: 0.4935 - val_accuracy: 0.7616\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4402 - accuracy: 0.7932 - val_loss: 0.5103 - val_accuracy: 0.7342\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4295 - accuracy: 0.8034 - val_loss: 0.4891 - val_accuracy: 0.7945\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4286 - accuracy: 0.7966 - val_loss: 0.4882 - val_accuracy: 0.7836\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4174 - accuracy: 0.8000 - val_loss: 0.5090 - val_accuracy: 0.7726\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4260 - accuracy: 0.7979 - val_loss: 0.5258 - val_accuracy: 0.7397\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4179 - accuracy: 0.8000 - val_loss: 0.5193 - val_accuracy: 0.7342\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4115 - accuracy: 0.8068 - val_loss: 0.5251 - val_accuracy: 0.7726\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4211 - accuracy: 0.7993 - val_loss: 0.5303 - val_accuracy: 0.7534\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 1s 28ms/step - loss: 0.4338 - accuracy: 0.7938 - val_loss: 0.5100 - val_accuracy: 0.7616\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4317 - accuracy: 0.7959 - val_loss: 0.5396 - val_accuracy: 0.7589\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4182 - accuracy: 0.8041 - val_loss: 0.5345 - val_accuracy: 0.7370\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4156 - accuracy: 0.8034 - val_loss: 0.4973 - val_accuracy: 0.7534\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4147 - accuracy: 0.8007 - val_loss: 0.5470 - val_accuracy: 0.7151\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4117 - accuracy: 0.8116 - val_loss: 0.5084 - val_accuracy: 0.7918\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4105 - accuracy: 0.8041 - val_loss: 0.5192 - val_accuracy: 0.7616\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4055 - accuracy: 0.8178 - val_loss: 0.5557 - val_accuracy: 0.7562\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.4011 - accuracy: 0.8151 - val_loss: 0.5291 - val_accuracy: 0.7726\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4128 - accuracy: 0.8103 - val_loss: 0.5461 - val_accuracy: 0.7753\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4101 - accuracy: 0.8034 - val_loss: 0.5490 - val_accuracy: 0.7589\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 1s 29ms/step - loss: 0.4247 - accuracy: 0.8062 - val_loss: 0.5941 - val_accuracy: 0.7479\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 0.4008 - accuracy: 0.8130 - val_loss: 0.5401 - val_accuracy: 0.7781\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.3933 - accuracy: 0.8144 - val_loss: 0.5312 - val_accuracy: 0.7616\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4098 - accuracy: 0.8137 - val_loss: 0.5142 - val_accuracy: 0.7671\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.4057 - accuracy: 0.8034 - val_loss: 0.5138 - val_accuracy: 0.7699\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.3971 - accuracy: 0.8212 - val_loss: 0.5154 - val_accuracy: 0.7836\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 1s 26ms/step - loss: 0.3979 - accuracy: 0.8075 - val_loss: 0.5656 - val_accuracy: 0.7479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6e5903910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(LSTM(units=100, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "rnn.add(LSTM(units=100, return_sequences=False))\n",
    "rnn.add(Dense(20, activation='relu'))\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "rnn.fit(X_train_lstm, y_train_lstm, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test_lstm), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.827405668893302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = rnn.predict(X_test_lstm)\n",
    "auc = roc_auc_score(y_test_lstm, y_pred)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) CNN (over features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train.reshape(int(X_train.shape[0]/24), -1, X_train.shape[1], 1)\t\t# shape: 1460 days (4 years), 24 hours, 6 features\n",
    "y_train_cnn = np.array(y)[:int(X_train_cnn.shape[0])]\n",
    "\n",
    "X_test_cnn = X_test.reshape(int(X_test.shape[0]/24), -1, X_test.shape[1], 1)\t\t\t# shape: 365 days (1 year), 24 hours, 6 features\n",
    "y_test_cnn = np.array(y)[int(X_train_cnn.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 24, 1, 32)\n",
      "(None, 768)\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4473 - val_loss: 0.4815\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4063 - val_loss: 0.4689\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 0.4177\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3478 - val_loss: 0.3834\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3934\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3692\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3211 - val_loss: 0.3843\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3863\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3142 - val_loss: 0.3637\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3613\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3583\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3018 - val_loss: 0.3501\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3028 - val_loss: 0.3739\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3078 - val_loss: 0.3461\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2996 - val_loss: 0.3505\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2969 - val_loss: 0.3394\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3420\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2971 - val_loss: 0.3394\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3450\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.3352\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2900 - val_loss: 0.3343\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2854 - val_loss: 0.3310\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3292\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2884 - val_loss: 0.3354\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.3329\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2786 - val_loss: 0.3339\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2784 - val_loss: 0.3269\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2824 - val_loss: 0.3247\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2804 - val_loss: 0.3246\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2804 - val_loss: 0.3336\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2774 - val_loss: 0.3206\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2735 - val_loss: 0.3178\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2749 - val_loss: 0.3165\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2752 - val_loss: 0.3128\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2713 - val_loss: 0.3199\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2696 - val_loss: 0.3166\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2764 - val_loss: 0.3133\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2685 - val_loss: 0.3090\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2673 - val_loss: 0.3131\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2680 - val_loss: 0.3164\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2674 - val_loss: 0.3141\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3140\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2635 - val_loss: 0.3081\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2644 - val_loss: 0.3035\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2647 - val_loss: 0.3089\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 0.3075\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2625 - val_loss: 0.3134\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2593 - val_loss: 0.3061\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2577 - val_loss: 0.3129\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2616 - val_loss: 0.3129\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.3023\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2553 - val_loss: 0.3055\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2564 - val_loss: 0.3223\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.3150\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2598 - val_loss: 0.3059\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2579 - val_loss: 0.3015\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.3065\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2578 - val_loss: 0.3121\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.3136\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2548 - val_loss: 0.3005\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2518 - val_loss: 0.3101\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2553 - val_loss: 0.2994\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2549 - val_loss: 0.3048\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2531 - val_loss: 0.2957\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2508 - val_loss: 0.3073\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2510 - val_loss: 0.3021\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2494 - val_loss: 0.2923\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2479 - val_loss: 0.3039\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2490 - val_loss: 0.3078\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2466 - val_loss: 0.2989\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2464 - val_loss: 0.2968\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2474 - val_loss: 0.2936\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2453 - val_loss: 0.2987\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2444 - val_loss: 0.2958\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2446 - val_loss: 0.2980\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2454 - val_loss: 0.2971\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2448 - val_loss: 0.2960\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2500 - val_loss: 0.3005\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2446 - val_loss: 0.2923\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2437 - val_loss: 0.2953\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2428 - val_loss: 0.3094\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2429 - val_loss: 0.2980\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2471 - val_loss: 0.2987\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2402 - val_loss: 0.2925\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2411 - val_loss: 0.2956\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2425 - val_loss: 0.2958\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2424 - val_loss: 0.2928\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2403 - val_loss: 0.2988\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2384 - val_loss: 0.2914\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2385 - val_loss: 0.2909\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2387 - val_loss: 0.2906\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2399 - val_loss: 0.2947\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2403 - val_loss: 0.2958\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2936\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2451 - val_loss: 0.2973\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2421 - val_loss: 0.2949\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2388 - val_loss: 0.2910\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2359 - val_loss: 0.2966\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2351 - val_loss: 0.2903\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2356 - val_loss: 0.2938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6ee0ff1c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "conv_layer = Conv2D(filters=32, kernel_size=(1, X_train_cnn.shape[2]), activation='relu', input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2], 1))\n",
    "cnn.add(conv_layer)\n",
    "print(conv_layer.output_shape)\n",
    "\n",
    "flatten_layer = Flatten()\n",
    "cnn.add(flatten_layer)\n",
    "print(flatten_layer.output_shape)\n",
    "\n",
    "cnn.add(Dense(20, activation='relu'))\n",
    "cnn.add(Dense(units=1))\n",
    "cnn.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "cnn.fit(X_train_cnn, y_train_cnn, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_cnn, y_test_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8248781368478064\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test_cnn)\n",
    "auc = roc_auc_score(y_test_cnn, y_pred)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) CNN (over time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 6, 32)\n",
      "(None, 192)\n",
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.4612 - val_loss: 0.4798\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4711\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3949 - val_loss: 0.4435\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.4247\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4246\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3533 - val_loss: 0.4095\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3543 - val_loss: 0.4117\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3442 - val_loss: 0.4021\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3416 - val_loss: 0.4079\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.3869\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3865\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3901\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3885\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3767\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3212 - val_loss: 0.3894\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3188 - val_loss: 0.3763\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3756\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3164 - val_loss: 0.3886\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3660\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3145 - val_loss: 0.3616\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3680\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3133 - val_loss: 0.3672\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3094 - val_loss: 0.3542\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3472\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3036 - val_loss: 0.3470\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3568\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3475\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3013 - val_loss: 0.3584\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3498\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.3449\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3563\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.3473\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3537\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.3448\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3347\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.3360\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2877 - val_loss: 0.3364\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3407\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.3286\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3464\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2863 - val_loss: 0.3364\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3325\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2868 - val_loss: 0.3313\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3335\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2812 - val_loss: 0.3369\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.3333\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.3280\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.3289\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2814 - val_loss: 0.3228\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2774 - val_loss: 0.3254\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2772 - val_loss: 0.3253\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3242\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2753 - val_loss: 0.3303\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.3215\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2752 - val_loss: 0.3220\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2697 - val_loss: 0.3236\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.3296\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2750 - val_loss: 0.3213\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.3331\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.3224\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.3344\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.3334\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.3264\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.3229\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2665 - val_loss: 0.3249\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2653 - val_loss: 0.3335\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3238\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2672 - val_loss: 0.3254\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2652 - val_loss: 0.3239\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2638 - val_loss: 0.3195\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2647 - val_loss: 0.3184\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2650 - val_loss: 0.3203\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2671 - val_loss: 0.3264\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.3246\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.3191\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2659 - val_loss: 0.3262\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2615 - val_loss: 0.3187\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2629 - val_loss: 0.3295\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2603 - val_loss: 0.3182\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2626 - val_loss: 0.3241\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2589 - val_loss: 0.3263\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2611 - val_loss: 0.3363\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2625 - val_loss: 0.3248\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2648 - val_loss: 0.3261\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.3222\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2572 - val_loss: 0.3309\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2588 - val_loss: 0.3212\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2582 - val_loss: 0.3110\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2544 - val_loss: 0.3142\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3204\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2568 - val_loss: 0.3227\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2590 - val_loss: 0.3297\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2578 - val_loss: 0.3326\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.3219\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2545 - val_loss: 0.3235\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2555 - val_loss: 0.3140\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2537 - val_loss: 0.3237\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.3214\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2525 - val_loss: 0.3127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6ef4ef8e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "conv_layer = Conv2D(filters=32, kernel_size=(24, 1), activation='relu', input_shape=(X_train_cnn.shape[1], X_train_cnn.shape[2], 1))\n",
    "cnn.add(conv_layer)\n",
    "print(conv_layer.output_shape)\n",
    "\n",
    "flatten_layer = Flatten()\n",
    "cnn.add(flatten_layer)\n",
    "print(flatten_layer.output_shape)\n",
    "\n",
    "cnn.add(Dense(20, activation='relu'))\n",
    "cnn.add(Dense(units=1))\n",
    "cnn.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "cnn.fit(X_train_cnn, y_train_cnn, epochs=100, batch_size=32, verbose=1, validation_data=(X_test_cnn, y_test_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8253896611903473\n"
     ]
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test_cnn)\n",
    "auc = roc_auc_score(y_test_cnn, y_pred)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN (flattened features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, df['hour']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['g'] = X.groupby('hour')['hour'].cumcount()\n",
    "X = X.set_index(['g','hour']).stack().unstack([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X.index) * 0.8)\n",
    "X_train_ann = X.iloc[:train_size, :]\n",
    "X_test_ann = X.iloc[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "X_train_ann = sc.fit_transform(X_train_ann)\n",
    "X_test_ann = sc.transform(X_test_ann)\n",
    "\n",
    "y_train_ann = np.array(y)[:int(X_train_ann.shape[0])]\n",
    "y_test_ann = np.array(y)[int(X_train_ann.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "46/46 [==============================] - 1s 3ms/step - loss: 0.6541 - accuracy: 0.6021 - val_loss: 0.6499 - val_accuracy: 0.5671\n",
      "Epoch 2/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.6911 - val_loss: 0.6077 - val_accuracy: 0.6685\n",
      "Epoch 3/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7260 - val_loss: 0.6116 - val_accuracy: 0.6247\n",
      "Epoch 4/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7315 - val_loss: 0.5708 - val_accuracy: 0.6986\n",
      "Epoch 5/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7418 - val_loss: 0.5690 - val_accuracy: 0.6712\n",
      "Epoch 6/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7486 - val_loss: 0.5682 - val_accuracy: 0.6932\n",
      "Epoch 7/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7274 - val_loss: 0.5511 - val_accuracy: 0.7041\n",
      "Epoch 8/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7233 - val_loss: 0.5918 - val_accuracy: 0.6712\n",
      "Epoch 9/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7541 - val_loss: 0.5595 - val_accuracy: 0.6986\n",
      "Epoch 10/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7548 - val_loss: 0.5635 - val_accuracy: 0.6986\n",
      "Epoch 11/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7534 - val_loss: 0.5499 - val_accuracy: 0.6877\n",
      "Epoch 12/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7500 - val_loss: 0.5468 - val_accuracy: 0.7205\n",
      "Epoch 13/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7568 - val_loss: 0.5458 - val_accuracy: 0.7041\n",
      "Epoch 14/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7651 - val_loss: 0.5451 - val_accuracy: 0.6959\n",
      "Epoch 15/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7699 - val_loss: 0.5316 - val_accuracy: 0.7315\n",
      "Epoch 16/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.5630 - val_accuracy: 0.7370\n",
      "Epoch 17/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7699 - val_loss: 0.5310 - val_accuracy: 0.7479\n",
      "Epoch 18/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7705 - val_loss: 0.5324 - val_accuracy: 0.7205\n",
      "Epoch 19/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7692 - val_loss: 0.5759 - val_accuracy: 0.7534\n",
      "Epoch 20/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.5259 - val_accuracy: 0.7507\n",
      "Epoch 21/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7678 - val_loss: 0.5346 - val_accuracy: 0.7315\n",
      "Epoch 22/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7767 - val_loss: 0.5509 - val_accuracy: 0.7644\n",
      "Epoch 23/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7658 - val_loss: 0.5818 - val_accuracy: 0.6685\n",
      "Epoch 24/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7767 - val_loss: 0.5382 - val_accuracy: 0.7616\n",
      "Epoch 25/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7740 - val_loss: 0.6115 - val_accuracy: 0.7260\n",
      "Epoch 26/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7774 - val_loss: 0.5431 - val_accuracy: 0.7397\n",
      "Epoch 27/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7822 - val_loss: 0.5580 - val_accuracy: 0.7123\n",
      "Epoch 28/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.5599 - val_accuracy: 0.6795\n",
      "Epoch 29/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7801 - val_loss: 0.5375 - val_accuracy: 0.7397\n",
      "Epoch 30/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7856 - val_loss: 0.5573 - val_accuracy: 0.7370\n",
      "Epoch 31/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7925 - val_loss: 0.5621 - val_accuracy: 0.6904\n",
      "Epoch 32/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7952 - val_loss: 0.5313 - val_accuracy: 0.7452\n",
      "Epoch 33/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7904 - val_loss: 0.5217 - val_accuracy: 0.7671\n",
      "Epoch 34/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7884 - val_loss: 0.5305 - val_accuracy: 0.7425\n",
      "Epoch 35/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7973 - val_loss: 0.5476 - val_accuracy: 0.7178\n",
      "Epoch 36/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7897 - val_loss: 0.5683 - val_accuracy: 0.7425\n",
      "Epoch 37/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7808 - val_loss: 0.5849 - val_accuracy: 0.6932\n",
      "Epoch 38/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7993 - val_loss: 0.5442 - val_accuracy: 0.7644\n",
      "Epoch 39/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7849 - val_loss: 0.5186 - val_accuracy: 0.7425\n",
      "Epoch 40/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4324 - accuracy: 0.7918 - val_loss: 0.5475 - val_accuracy: 0.7068\n",
      "Epoch 41/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7870 - val_loss: 0.5424 - val_accuracy: 0.7753\n",
      "Epoch 42/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8007 - val_loss: 0.5320 - val_accuracy: 0.7671\n",
      "Epoch 43/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7822 - val_loss: 0.5478 - val_accuracy: 0.6849\n",
      "Epoch 44/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7890 - val_loss: 0.5574 - val_accuracy: 0.6740\n",
      "Epoch 45/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7890 - val_loss: 0.5726 - val_accuracy: 0.7370\n",
      "Epoch 46/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7959 - val_loss: 0.5083 - val_accuracy: 0.7452\n",
      "Epoch 47/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4184 - accuracy: 0.8041 - val_loss: 0.5433 - val_accuracy: 0.7479\n",
      "Epoch 48/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7966 - val_loss: 0.5249 - val_accuracy: 0.7397\n",
      "Epoch 49/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.7938 - val_loss: 0.5509 - val_accuracy: 0.7452\n",
      "Epoch 50/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.7932 - val_loss: 0.5260 - val_accuracy: 0.7178\n",
      "Epoch 51/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.8007 - val_loss: 0.5149 - val_accuracy: 0.7616\n",
      "Epoch 52/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8048 - val_loss: 0.5432 - val_accuracy: 0.7397\n",
      "Epoch 53/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8075 - val_loss: 0.5692 - val_accuracy: 0.7425\n",
      "Epoch 54/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8041 - val_loss: 0.5116 - val_accuracy: 0.7507\n",
      "Epoch 55/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8014 - val_loss: 0.5407 - val_accuracy: 0.7014\n",
      "Epoch 56/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8021 - val_loss: 0.5381 - val_accuracy: 0.7589\n",
      "Epoch 57/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4187 - accuracy: 0.8137 - val_loss: 0.5208 - val_accuracy: 0.7644\n",
      "Epoch 58/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8000 - val_loss: 0.5273 - val_accuracy: 0.7671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8048 - val_loss: 0.5406 - val_accuracy: 0.7671\n",
      "Epoch 60/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8055 - val_loss: 0.5321 - val_accuracy: 0.7726\n",
      "Epoch 61/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4111 - accuracy: 0.8075 - val_loss: 0.5261 - val_accuracy: 0.7507\n",
      "Epoch 62/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4007 - accuracy: 0.8144 - val_loss: 0.5521 - val_accuracy: 0.6904\n",
      "Epoch 63/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8089 - val_loss: 0.5572 - val_accuracy: 0.7479\n",
      "Epoch 64/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8123 - val_loss: 0.5322 - val_accuracy: 0.7534\n",
      "Epoch 65/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4037 - accuracy: 0.8110 - val_loss: 0.5745 - val_accuracy: 0.6822\n",
      "Epoch 66/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4090 - accuracy: 0.8041 - val_loss: 0.5107 - val_accuracy: 0.7589\n",
      "Epoch 67/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8123 - val_loss: 0.5021 - val_accuracy: 0.7425\n",
      "Epoch 68/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8185 - val_loss: 0.5136 - val_accuracy: 0.7370\n",
      "Epoch 69/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8021 - val_loss: 0.5582 - val_accuracy: 0.7452\n",
      "Epoch 70/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8103 - val_loss: 0.5158 - val_accuracy: 0.7589\n",
      "Epoch 71/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8082 - val_loss: 0.5956 - val_accuracy: 0.7041\n",
      "Epoch 72/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8041 - val_loss: 0.5505 - val_accuracy: 0.7342\n",
      "Epoch 73/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8110 - val_loss: 0.5409 - val_accuracy: 0.7452\n",
      "Epoch 74/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8089 - val_loss: 0.5413 - val_accuracy: 0.7260\n",
      "Epoch 75/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8082 - val_loss: 0.5224 - val_accuracy: 0.7644\n",
      "Epoch 76/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8041 - val_loss: 0.5284 - val_accuracy: 0.7589\n",
      "Epoch 77/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3913 - accuracy: 0.8171 - val_loss: 0.5294 - val_accuracy: 0.7616\n",
      "Epoch 78/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8137 - val_loss: 0.5335 - val_accuracy: 0.7589\n",
      "Epoch 79/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8041 - val_loss: 0.5579 - val_accuracy: 0.6932\n",
      "Epoch 80/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8164 - val_loss: 0.5239 - val_accuracy: 0.7397\n",
      "Epoch 81/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8068 - val_loss: 0.5825 - val_accuracy: 0.7534\n",
      "Epoch 82/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8144 - val_loss: 0.5211 - val_accuracy: 0.7671\n",
      "Epoch 83/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8034 - val_loss: 0.5232 - val_accuracy: 0.7178\n",
      "Epoch 84/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.8151 - val_loss: 0.5798 - val_accuracy: 0.6932\n",
      "Epoch 85/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8137 - val_loss: 0.5266 - val_accuracy: 0.7452\n",
      "Epoch 86/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8247 - val_loss: 0.5416 - val_accuracy: 0.7260\n",
      "Epoch 87/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8082 - val_loss: 0.5581 - val_accuracy: 0.7288\n",
      "Epoch 88/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3974 - accuracy: 0.8178 - val_loss: 0.5092 - val_accuracy: 0.7507\n",
      "Epoch 89/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8082 - val_loss: 0.5127 - val_accuracy: 0.7425\n",
      "Epoch 90/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8116 - val_loss: 0.5123 - val_accuracy: 0.7452\n",
      "Epoch 91/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3810 - accuracy: 0.8274 - val_loss: 0.5132 - val_accuracy: 0.7479\n",
      "Epoch 92/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8274 - val_loss: 0.5579 - val_accuracy: 0.7260\n",
      "Epoch 93/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8164 - val_loss: 0.4984 - val_accuracy: 0.7671\n",
      "Epoch 94/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8185 - val_loss: 0.5667 - val_accuracy: 0.7562\n",
      "Epoch 95/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8240 - val_loss: 0.5500 - val_accuracy: 0.7315\n",
      "Epoch 96/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8247 - val_loss: 0.5273 - val_accuracy: 0.7397\n",
      "Epoch 97/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8315 - val_loss: 0.5417 - val_accuracy: 0.7370\n",
      "Epoch 98/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8267 - val_loss: 0.5228 - val_accuracy: 0.7397\n",
      "Epoch 99/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8158 - val_loss: 0.6339 - val_accuracy: 0.6986\n",
      "Epoch 100/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8089 - val_loss: 0.5495 - val_accuracy: 0.7205\n",
      "Epoch 101/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8110 - val_loss: 0.5074 - val_accuracy: 0.7726\n",
      "Epoch 102/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8253 - val_loss: 0.5564 - val_accuracy: 0.7534\n",
      "Epoch 103/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8253 - val_loss: 0.5400 - val_accuracy: 0.7288\n",
      "Epoch 104/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8233 - val_loss: 0.5310 - val_accuracy: 0.7589\n",
      "Epoch 105/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8342 - val_loss: 0.5315 - val_accuracy: 0.7397\n",
      "Epoch 106/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8322 - val_loss: 0.5076 - val_accuracy: 0.7753\n",
      "Epoch 107/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8199 - val_loss: 0.5484 - val_accuracy: 0.7260\n",
      "Epoch 108/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3758 - accuracy: 0.8219 - val_loss: 0.5489 - val_accuracy: 0.7507\n",
      "Epoch 109/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8253 - val_loss: 0.5091 - val_accuracy: 0.7534\n",
      "Epoch 110/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8233 - val_loss: 0.5470 - val_accuracy: 0.7315\n",
      "Epoch 111/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8315 - val_loss: 0.5207 - val_accuracy: 0.7562\n",
      "Epoch 112/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8185 - val_loss: 0.6036 - val_accuracy: 0.7151\n",
      "Epoch 113/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8158 - val_loss: 0.5390 - val_accuracy: 0.7397\n",
      "Epoch 114/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3640 - accuracy: 0.8349 - val_loss: 0.5394 - val_accuracy: 0.7315\n",
      "Epoch 115/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8219 - val_loss: 0.5562 - val_accuracy: 0.7178\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8171 - val_loss: 0.5545 - val_accuracy: 0.7397\n",
      "Epoch 117/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8253 - val_loss: 0.5532 - val_accuracy: 0.7342\n",
      "Epoch 118/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8322 - val_loss: 0.5449 - val_accuracy: 0.7233\n",
      "Epoch 119/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8267 - val_loss: 0.5183 - val_accuracy: 0.7726\n",
      "Epoch 120/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.8315 - val_loss: 0.5495 - val_accuracy: 0.7534\n",
      "Epoch 121/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8308 - val_loss: 0.5529 - val_accuracy: 0.7315\n",
      "Epoch 122/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8356 - val_loss: 0.5723 - val_accuracy: 0.7178\n",
      "Epoch 123/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8151 - val_loss: 0.5410 - val_accuracy: 0.7534\n",
      "Epoch 124/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8281 - val_loss: 0.6000 - val_accuracy: 0.7178\n",
      "Epoch 125/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8144 - val_loss: 0.5876 - val_accuracy: 0.7096\n",
      "Epoch 126/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8247 - val_loss: 0.5947 - val_accuracy: 0.7096\n",
      "Epoch 127/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8329 - val_loss: 0.5731 - val_accuracy: 0.6986\n",
      "Epoch 128/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8288 - val_loss: 0.5564 - val_accuracy: 0.7397\n",
      "Epoch 129/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.8377 - val_loss: 0.5335 - val_accuracy: 0.7507\n",
      "Epoch 130/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8404 - val_loss: 0.5451 - val_accuracy: 0.7425\n",
      "Epoch 131/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8233 - val_loss: 0.5485 - val_accuracy: 0.7315\n",
      "Epoch 132/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8404 - val_loss: 0.5533 - val_accuracy: 0.7562\n",
      "Epoch 133/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8349 - val_loss: 0.5104 - val_accuracy: 0.7507\n",
      "Epoch 134/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8336 - val_loss: 0.5447 - val_accuracy: 0.7260\n",
      "Epoch 135/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8370 - val_loss: 0.5513 - val_accuracy: 0.7616\n",
      "Epoch 136/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8336 - val_loss: 0.5490 - val_accuracy: 0.7397\n",
      "Epoch 137/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8377 - val_loss: 0.5422 - val_accuracy: 0.7288\n",
      "Epoch 138/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8342 - val_loss: 0.5430 - val_accuracy: 0.7616\n",
      "Epoch 139/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8308 - val_loss: 0.5721 - val_accuracy: 0.7370\n",
      "Epoch 140/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8370 - val_loss: 0.5219 - val_accuracy: 0.7589\n",
      "Epoch 141/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8425 - val_loss: 0.5914 - val_accuracy: 0.7288\n",
      "Epoch 142/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8370 - val_loss: 0.5906 - val_accuracy: 0.7096\n",
      "Epoch 143/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8418 - val_loss: 0.6258 - val_accuracy: 0.7123\n",
      "Epoch 144/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8329 - val_loss: 0.5137 - val_accuracy: 0.7644\n",
      "Epoch 145/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8384 - val_loss: 0.5534 - val_accuracy: 0.7534\n",
      "Epoch 146/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8295 - val_loss: 0.5619 - val_accuracy: 0.7397\n",
      "Epoch 147/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8253 - val_loss: 0.5301 - val_accuracy: 0.7534\n",
      "Epoch 148/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8336 - val_loss: 0.5587 - val_accuracy: 0.7644\n",
      "Epoch 149/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8411 - val_loss: 0.5292 - val_accuracy: 0.7699\n",
      "Epoch 150/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8466 - val_loss: 0.5846 - val_accuracy: 0.7315\n",
      "Epoch 151/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8308 - val_loss: 0.5728 - val_accuracy: 0.7562\n",
      "Epoch 152/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8404 - val_loss: 0.5435 - val_accuracy: 0.7534\n",
      "Epoch 153/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8377 - val_loss: 0.5722 - val_accuracy: 0.7233\n",
      "Epoch 154/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8432 - val_loss: 0.6189 - val_accuracy: 0.7342\n",
      "Epoch 155/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8514 - val_loss: 0.6102 - val_accuracy: 0.7205\n",
      "Epoch 156/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.8377 - val_loss: 0.5373 - val_accuracy: 0.7808\n",
      "Epoch 157/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8384 - val_loss: 0.5476 - val_accuracy: 0.7507\n",
      "Epoch 158/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8479 - val_loss: 0.5778 - val_accuracy: 0.7342\n",
      "Epoch 159/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8493 - val_loss: 0.6369 - val_accuracy: 0.7288\n",
      "Epoch 160/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8459 - val_loss: 0.5795 - val_accuracy: 0.7178\n",
      "Epoch 161/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8411 - val_loss: 0.5919 - val_accuracy: 0.7151\n",
      "Epoch 162/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8349 - val_loss: 0.5539 - val_accuracy: 0.7616\n",
      "Epoch 163/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8390 - val_loss: 0.5827 - val_accuracy: 0.7425\n",
      "Epoch 164/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8384 - val_loss: 0.5938 - val_accuracy: 0.7342\n",
      "Epoch 165/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8452 - val_loss: 0.5958 - val_accuracy: 0.7589\n",
      "Epoch 166/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8432 - val_loss: 0.5216 - val_accuracy: 0.7726\n",
      "Epoch 167/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8534 - val_loss: 0.5423 - val_accuracy: 0.7699\n",
      "Epoch 168/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8445 - val_loss: 0.6167 - val_accuracy: 0.6959\n",
      "Epoch 169/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8295 - val_loss: 0.5542 - val_accuracy: 0.7562\n",
      "Epoch 170/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3529 - accuracy: 0.8349 - val_loss: 0.5912 - val_accuracy: 0.7616\n",
      "Epoch 171/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8452 - val_loss: 0.5527 - val_accuracy: 0.7342\n",
      "Epoch 172/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8479 - val_loss: 0.5749 - val_accuracy: 0.7397\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8377 - val_loss: 0.5964 - val_accuracy: 0.7151\n",
      "Epoch 174/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8534 - val_loss: 0.5813 - val_accuracy: 0.7315\n",
      "Epoch 175/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8527 - val_loss: 0.5494 - val_accuracy: 0.7562\n",
      "Epoch 176/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8548 - val_loss: 0.5553 - val_accuracy: 0.7781\n",
      "Epoch 177/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3519 - accuracy: 0.8322 - val_loss: 0.5844 - val_accuracy: 0.7425\n",
      "Epoch 178/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8507 - val_loss: 0.5735 - val_accuracy: 0.7534\n",
      "Epoch 179/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8555 - val_loss: 0.5668 - val_accuracy: 0.7397\n",
      "Epoch 180/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8459 - val_loss: 0.5890 - val_accuracy: 0.7315\n",
      "Epoch 181/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8500 - val_loss: 0.5378 - val_accuracy: 0.7699\n",
      "Epoch 182/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8568 - val_loss: 0.5685 - val_accuracy: 0.7397\n",
      "Epoch 183/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8425 - val_loss: 0.5777 - val_accuracy: 0.7370\n",
      "Epoch 184/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8445 - val_loss: 0.5927 - val_accuracy: 0.7288\n",
      "Epoch 185/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8521 - val_loss: 0.5633 - val_accuracy: 0.7534\n",
      "Epoch 186/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8568 - val_loss: 0.5918 - val_accuracy: 0.7370\n",
      "Epoch 187/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8575 - val_loss: 0.5594 - val_accuracy: 0.7562\n",
      "Epoch 188/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8555 - val_loss: 0.5862 - val_accuracy: 0.7479\n",
      "Epoch 189/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3246 - accuracy: 0.8534 - val_loss: 0.5497 - val_accuracy: 0.7753\n",
      "Epoch 190/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8466 - val_loss: 0.6010 - val_accuracy: 0.7342\n",
      "Epoch 191/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8438 - val_loss: 0.5716 - val_accuracy: 0.7342\n",
      "Epoch 192/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8548 - val_loss: 0.5672 - val_accuracy: 0.7288\n",
      "Epoch 193/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8459 - val_loss: 0.6448 - val_accuracy: 0.7041\n",
      "Epoch 194/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8479 - val_loss: 0.5472 - val_accuracy: 0.7671\n",
      "Epoch 195/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.8568 - val_loss: 0.5627 - val_accuracy: 0.7562\n",
      "Epoch 196/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8418 - val_loss: 0.5799 - val_accuracy: 0.7507\n",
      "Epoch 197/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8568 - val_loss: 0.5797 - val_accuracy: 0.7479\n",
      "Epoch 198/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8521 - val_loss: 0.5975 - val_accuracy: 0.7562\n",
      "Epoch 199/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8555 - val_loss: 0.5955 - val_accuracy: 0.7616\n",
      "Epoch 200/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8589 - val_loss: 0.5989 - val_accuracy: 0.7425\n",
      "Epoch 201/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8493 - val_loss: 0.6421 - val_accuracy: 0.7452\n",
      "Epoch 202/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3126 - accuracy: 0.8507 - val_loss: 0.5713 - val_accuracy: 0.7534\n",
      "Epoch 203/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8418 - val_loss: 0.6641 - val_accuracy: 0.7534\n",
      "Epoch 204/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8568 - val_loss: 0.5863 - val_accuracy: 0.7370\n",
      "Epoch 205/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3168 - accuracy: 0.8507 - val_loss: 0.5681 - val_accuracy: 0.7781\n",
      "Epoch 206/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3189 - accuracy: 0.8527 - val_loss: 0.5898 - val_accuracy: 0.7589\n",
      "Epoch 207/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.8705 - val_loss: 0.5680 - val_accuracy: 0.7781\n",
      "Epoch 208/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3138 - accuracy: 0.8575 - val_loss: 0.5803 - val_accuracy: 0.7671\n",
      "Epoch 209/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3158 - accuracy: 0.8500 - val_loss: 0.6037 - val_accuracy: 0.7425\n",
      "Epoch 210/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.8562 - val_loss: 0.5785 - val_accuracy: 0.7479\n",
      "Epoch 211/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3133 - accuracy: 0.8582 - val_loss: 0.5847 - val_accuracy: 0.7534\n",
      "Epoch 212/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.8568 - val_loss: 0.6056 - val_accuracy: 0.7644\n",
      "Epoch 213/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8610 - val_loss: 0.6836 - val_accuracy: 0.7205\n",
      "Epoch 214/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8514 - val_loss: 0.6056 - val_accuracy: 0.7644\n",
      "Epoch 215/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3068 - accuracy: 0.8616 - val_loss: 0.5954 - val_accuracy: 0.7562\n",
      "Epoch 216/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3020 - accuracy: 0.8568 - val_loss: 0.6243 - val_accuracy: 0.7425\n",
      "Epoch 217/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3122 - accuracy: 0.8610 - val_loss: 0.6300 - val_accuracy: 0.7397\n",
      "Epoch 218/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2956 - accuracy: 0.8699 - val_loss: 0.6240 - val_accuracy: 0.7425\n",
      "Epoch 219/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.8596 - val_loss: 0.7124 - val_accuracy: 0.7178\n",
      "Epoch 220/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8623 - val_loss: 0.6221 - val_accuracy: 0.7260\n",
      "Epoch 221/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2966 - accuracy: 0.8733 - val_loss: 0.6907 - val_accuracy: 0.7342\n",
      "Epoch 222/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3095 - accuracy: 0.8568 - val_loss: 0.6024 - val_accuracy: 0.7562\n",
      "Epoch 223/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8541 - val_loss: 0.6336 - val_accuracy: 0.7342\n",
      "Epoch 224/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2974 - accuracy: 0.8726 - val_loss: 0.6663 - val_accuracy: 0.7315\n",
      "Epoch 225/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3106 - accuracy: 0.8534 - val_loss: 0.6741 - val_accuracy: 0.7315\n",
      "Epoch 226/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8747 - val_loss: 0.6536 - val_accuracy: 0.7452\n",
      "Epoch 227/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3028 - accuracy: 0.8658 - val_loss: 0.6881 - val_accuracy: 0.7123\n",
      "Epoch 228/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2988 - accuracy: 0.8705 - val_loss: 0.6587 - val_accuracy: 0.7205\n",
      "Epoch 229/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8603 - val_loss: 0.6183 - val_accuracy: 0.7479\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.8664 - val_loss: 0.5704 - val_accuracy: 0.7890\n",
      "Epoch 231/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2942 - accuracy: 0.8664 - val_loss: 0.6414 - val_accuracy: 0.7342\n",
      "Epoch 232/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8432 - val_loss: 0.6457 - val_accuracy: 0.7397\n",
      "Epoch 233/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8356 - val_loss: 0.5884 - val_accuracy: 0.7644\n",
      "Epoch 234/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3016 - accuracy: 0.8630 - val_loss: 0.6285 - val_accuracy: 0.7315\n",
      "Epoch 235/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8644 - val_loss: 0.6124 - val_accuracy: 0.7507\n",
      "Epoch 236/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8719 - val_loss: 0.6373 - val_accuracy: 0.7342\n",
      "Epoch 237/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8685 - val_loss: 0.6230 - val_accuracy: 0.7534\n",
      "Epoch 238/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2865 - accuracy: 0.8760 - val_loss: 0.6893 - val_accuracy: 0.7123\n",
      "Epoch 239/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8616 - val_loss: 0.5778 - val_accuracy: 0.7836\n",
      "Epoch 240/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2934 - accuracy: 0.8685 - val_loss: 0.5873 - val_accuracy: 0.7507\n",
      "Epoch 241/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8753 - val_loss: 0.6054 - val_accuracy: 0.7644\n",
      "Epoch 242/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8644 - val_loss: 0.6244 - val_accuracy: 0.7562\n",
      "Epoch 243/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.8678 - val_loss: 0.6600 - val_accuracy: 0.7260\n",
      "Epoch 244/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8692 - val_loss: 0.7036 - val_accuracy: 0.7315\n",
      "Epoch 245/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8719 - val_loss: 0.6275 - val_accuracy: 0.7507\n",
      "Epoch 246/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2874 - accuracy: 0.8733 - val_loss: 0.6253 - val_accuracy: 0.7397\n",
      "Epoch 247/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2838 - accuracy: 0.8740 - val_loss: 0.6175 - val_accuracy: 0.7534\n",
      "Epoch 248/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2860 - accuracy: 0.8740 - val_loss: 0.6514 - val_accuracy: 0.7534\n",
      "Epoch 249/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8747 - val_loss: 0.6333 - val_accuracy: 0.7315\n",
      "Epoch 250/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.8637 - val_loss: 0.6693 - val_accuracy: 0.7233\n",
      "Epoch 251/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2882 - accuracy: 0.8747 - val_loss: 0.6132 - val_accuracy: 0.7699\n",
      "Epoch 252/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2844 - accuracy: 0.8692 - val_loss: 0.6186 - val_accuracy: 0.7699\n",
      "Epoch 253/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8623 - val_loss: 0.6530 - val_accuracy: 0.7397\n",
      "Epoch 254/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2721 - accuracy: 0.8822 - val_loss: 0.6529 - val_accuracy: 0.7342\n",
      "Epoch 255/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2999 - accuracy: 0.8651 - val_loss: 0.6455 - val_accuracy: 0.7589\n",
      "Epoch 256/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8815 - val_loss: 0.6310 - val_accuracy: 0.7452\n",
      "Epoch 257/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2706 - accuracy: 0.8836 - val_loss: 0.7217 - val_accuracy: 0.7178\n",
      "Epoch 258/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8760 - val_loss: 0.7666 - val_accuracy: 0.7260\n",
      "Epoch 259/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2953 - accuracy: 0.8630 - val_loss: 0.6673 - val_accuracy: 0.7452\n",
      "Epoch 260/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8705 - val_loss: 0.6696 - val_accuracy: 0.7452\n",
      "Epoch 261/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2788 - accuracy: 0.8795 - val_loss: 0.6756 - val_accuracy: 0.7315\n",
      "Epoch 262/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8500 - val_loss: 0.7887 - val_accuracy: 0.7014\n",
      "Epoch 263/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3161 - accuracy: 0.8562 - val_loss: 0.7086 - val_accuracy: 0.7233\n",
      "Epoch 264/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2840 - accuracy: 0.8767 - val_loss: 0.7437 - val_accuracy: 0.7452\n",
      "Epoch 265/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.78 - 0s 1ms/step - loss: 0.3152 - accuracy: 0.8500 - val_loss: 0.6786 - val_accuracy: 0.7370\n",
      "Epoch 266/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8678 - val_loss: 0.6864 - val_accuracy: 0.7452\n",
      "Epoch 267/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2805 - accuracy: 0.8712 - val_loss: 0.6580 - val_accuracy: 0.7397\n",
      "Epoch 268/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2736 - accuracy: 0.8774 - val_loss: 0.7239 - val_accuracy: 0.7342\n",
      "Epoch 269/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2733 - accuracy: 0.8801 - val_loss: 0.6723 - val_accuracy: 0.7342\n",
      "Epoch 270/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.8856 - val_loss: 0.6764 - val_accuracy: 0.7397\n",
      "Epoch 271/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2699 - accuracy: 0.8849 - val_loss: 0.6595 - val_accuracy: 0.7616\n",
      "Epoch 272/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2778 - accuracy: 0.8767 - val_loss: 0.6618 - val_accuracy: 0.7370\n",
      "Epoch 273/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.8801 - val_loss: 0.6511 - val_accuracy: 0.7534\n",
      "Epoch 274/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2914 - accuracy: 0.8719 - val_loss: 0.7084 - val_accuracy: 0.7315\n",
      "Epoch 275/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8699 - val_loss: 0.6598 - val_accuracy: 0.7507\n",
      "Epoch 276/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8644 - val_loss: 0.6423 - val_accuracy: 0.7699\n",
      "Epoch 277/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8822 - val_loss: 0.7048 - val_accuracy: 0.7507\n",
      "Epoch 278/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.8610 - val_loss: 0.6202 - val_accuracy: 0.7671\n",
      "Epoch 279/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2701 - accuracy: 0.8829 - val_loss: 0.7442 - val_accuracy: 0.7397\n",
      "Epoch 280/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8767 - val_loss: 0.7066 - val_accuracy: 0.7534\n",
      "Epoch 281/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8822 - val_loss: 0.7533 - val_accuracy: 0.7205\n",
      "Epoch 282/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.8781 - val_loss: 0.7736 - val_accuracy: 0.7288\n",
      "Epoch 283/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2712 - accuracy: 0.8747 - val_loss: 0.7223 - val_accuracy: 0.7370\n",
      "Epoch 284/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.8788 - val_loss: 0.7259 - val_accuracy: 0.7151\n",
      "Epoch 285/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2845 - accuracy: 0.8740 - val_loss: 0.7888 - val_accuracy: 0.7342\n",
      "Epoch 286/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2821 - accuracy: 0.8747 - val_loss: 0.6892 - val_accuracy: 0.7534\n",
      "Epoch 287/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.8815 - val_loss: 0.7820 - val_accuracy: 0.7233\n",
      "Epoch 288/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.8760 - val_loss: 0.7357 - val_accuracy: 0.7370\n",
      "Epoch 289/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.8781 - val_loss: 0.6425 - val_accuracy: 0.7562\n",
      "Epoch 290/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.8712 - val_loss: 0.7248 - val_accuracy: 0.7562\n",
      "Epoch 291/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2648 - accuracy: 0.8829 - val_loss: 0.7897 - val_accuracy: 0.7068\n",
      "Epoch 292/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.8836 - val_loss: 0.7208 - val_accuracy: 0.7479\n",
      "Epoch 293/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2562 - accuracy: 0.8884 - val_loss: 0.6963 - val_accuracy: 0.7562\n",
      "Epoch 294/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.8863 - val_loss: 0.7674 - val_accuracy: 0.7616\n",
      "Epoch 295/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8692 - val_loss: 0.7338 - val_accuracy: 0.7288\n",
      "Epoch 296/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.8884 - val_loss: 0.6866 - val_accuracy: 0.7479\n",
      "Epoch 297/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2731 - accuracy: 0.8719 - val_loss: 0.7150 - val_accuracy: 0.7534\n",
      "Epoch 298/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2624 - accuracy: 0.8877 - val_loss: 0.7527 - val_accuracy: 0.7315\n",
      "Epoch 299/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8767 - val_loss: 0.6740 - val_accuracy: 0.7644\n",
      "Epoch 300/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8918 - val_loss: 0.7267 - val_accuracy: 0.7260\n",
      "Epoch 301/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2555 - accuracy: 0.8897 - val_loss: 0.7085 - val_accuracy: 0.7397\n",
      "Epoch 302/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2583 - accuracy: 0.8911 - val_loss: 0.7211 - val_accuracy: 0.7562\n",
      "Epoch 303/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.8925 - val_loss: 0.7029 - val_accuracy: 0.7479\n",
      "Epoch 304/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.8877 - val_loss: 0.8442 - val_accuracy: 0.7096\n",
      "Epoch 305/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.8705 - val_loss: 0.8604 - val_accuracy: 0.7096\n",
      "Epoch 306/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8445 - val_loss: 0.6972 - val_accuracy: 0.7452\n",
      "Epoch 307/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8747 - val_loss: 0.7132 - val_accuracy: 0.7562\n",
      "Epoch 308/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2656 - accuracy: 0.8822 - val_loss: 0.6516 - val_accuracy: 0.7836\n",
      "Epoch 309/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2669 - accuracy: 0.8815 - val_loss: 0.7969 - val_accuracy: 0.7205\n",
      "Epoch 310/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2621 - accuracy: 0.8856 - val_loss: 0.7049 - val_accuracy: 0.7452\n",
      "Epoch 311/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.8822 - val_loss: 0.6842 - val_accuracy: 0.7452\n",
      "Epoch 312/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2561 - accuracy: 0.8863 - val_loss: 0.8035 - val_accuracy: 0.7288\n",
      "Epoch 313/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2618 - accuracy: 0.8870 - val_loss: 0.8173 - val_accuracy: 0.7096\n",
      "Epoch 314/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.8904 - val_loss: 0.8017 - val_accuracy: 0.7151\n",
      "Epoch 315/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8945 - val_loss: 0.7318 - val_accuracy: 0.7479\n",
      "Epoch 316/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2580 - accuracy: 0.8829 - val_loss: 0.7837 - val_accuracy: 0.7342\n",
      "Epoch 317/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.8918 - val_loss: 0.7443 - val_accuracy: 0.7534\n",
      "Epoch 318/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.8932 - val_loss: 0.8595 - val_accuracy: 0.7014\n",
      "Epoch 319/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8945 - val_loss: 0.7777 - val_accuracy: 0.7397\n",
      "Epoch 320/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.8904 - val_loss: 0.8264 - val_accuracy: 0.7178\n",
      "Epoch 321/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2516 - accuracy: 0.8863 - val_loss: 0.7555 - val_accuracy: 0.7479\n",
      "Epoch 322/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.8863 - val_loss: 0.7264 - val_accuracy: 0.7507\n",
      "Epoch 323/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8877 - val_loss: 0.7417 - val_accuracy: 0.7562\n",
      "Epoch 324/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.8938 - val_loss: 0.7459 - val_accuracy: 0.7589\n",
      "Epoch 325/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8911 - val_loss: 0.7425 - val_accuracy: 0.7397\n",
      "Epoch 326/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.8932 - val_loss: 0.7321 - val_accuracy: 0.7644\n",
      "Epoch 327/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2390 - accuracy: 0.9000 - val_loss: 0.7458 - val_accuracy: 0.7370\n",
      "Epoch 328/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.8890 - val_loss: 0.8074 - val_accuracy: 0.7370\n",
      "Epoch 329/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8863 - val_loss: 0.7662 - val_accuracy: 0.7315\n",
      "Epoch 330/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.8918 - val_loss: 0.7820 - val_accuracy: 0.7452\n",
      "Epoch 331/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.8945 - val_loss: 0.7936 - val_accuracy: 0.7452\n",
      "Epoch 332/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8836 - val_loss: 0.7677 - val_accuracy: 0.7452\n",
      "Epoch 333/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.8945 - val_loss: 0.8138 - val_accuracy: 0.7534\n",
      "Epoch 334/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.8870 - val_loss: 0.7720 - val_accuracy: 0.7342\n",
      "Epoch 335/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8856 - val_loss: 0.7365 - val_accuracy: 0.7644\n",
      "Epoch 336/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.8829 - val_loss: 0.7088 - val_accuracy: 0.7589\n",
      "Epoch 337/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.8979 - val_loss: 0.7277 - val_accuracy: 0.7562\n",
      "Epoch 338/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.8856 - val_loss: 0.7225 - val_accuracy: 0.7397\n",
      "Epoch 339/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2651 - accuracy: 0.8870 - val_loss: 0.8216 - val_accuracy: 0.7370\n",
      "Epoch 340/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.8911 - val_loss: 0.8205 - val_accuracy: 0.7205\n",
      "Epoch 341/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.8918 - val_loss: 0.9026 - val_accuracy: 0.7205\n",
      "Epoch 342/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9000 - val_loss: 0.8597 - val_accuracy: 0.7397\n",
      "Epoch 343/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2429 - accuracy: 0.8897 - val_loss: 0.7331 - val_accuracy: 0.7315\n",
      "Epoch 344/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.9014 - val_loss: 0.9720 - val_accuracy: 0.6904\n",
      "Epoch 345/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8979 - val_loss: 0.7401 - val_accuracy: 0.7699\n",
      "Epoch 346/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2393 - accuracy: 0.8952 - val_loss: 0.7716 - val_accuracy: 0.7562\n",
      "Epoch 347/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.8897 - val_loss: 0.8020 - val_accuracy: 0.7233\n",
      "Epoch 348/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.8884 - val_loss: 0.7198 - val_accuracy: 0.7562\n",
      "Epoch 349/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8897 - val_loss: 0.7882 - val_accuracy: 0.7562\n",
      "Epoch 350/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2388 - accuracy: 0.8897 - val_loss: 0.8683 - val_accuracy: 0.7014\n",
      "Epoch 351/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8904 - val_loss: 0.8354 - val_accuracy: 0.7233\n",
      "Epoch 352/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.8966 - val_loss: 0.8057 - val_accuracy: 0.7397\n",
      "Epoch 353/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8884 - val_loss: 0.8351 - val_accuracy: 0.7178\n",
      "Epoch 354/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2513 - accuracy: 0.8925 - val_loss: 0.7475 - val_accuracy: 0.7479\n",
      "Epoch 355/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.8938 - val_loss: 0.7774 - val_accuracy: 0.7452\n",
      "Epoch 356/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9021 - val_loss: 0.7596 - val_accuracy: 0.7534\n",
      "Epoch 357/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2317 - accuracy: 0.8945 - val_loss: 0.8540 - val_accuracy: 0.7452\n",
      "Epoch 358/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9089 - val_loss: 0.7505 - val_accuracy: 0.7479\n",
      "Epoch 359/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.8959 - val_loss: 0.8138 - val_accuracy: 0.7452\n",
      "Epoch 360/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.9034 - val_loss: 0.7305 - val_accuracy: 0.7589\n",
      "Epoch 361/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.9110 - val_loss: 0.7809 - val_accuracy: 0.7288\n",
      "Epoch 362/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9041 - val_loss: 0.9419 - val_accuracy: 0.7260\n",
      "Epoch 363/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9041 - val_loss: 0.9154 - val_accuracy: 0.7260\n",
      "Epoch 364/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9062 - val_loss: 0.8371 - val_accuracy: 0.7260\n",
      "Epoch 365/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.8932 - val_loss: 0.7578 - val_accuracy: 0.7699\n",
      "Epoch 366/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.9021 - val_loss: 0.8235 - val_accuracy: 0.7534\n",
      "Epoch 367/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9027 - val_loss: 0.8862 - val_accuracy: 0.7151\n",
      "Epoch 368/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2340 - accuracy: 0.8938 - val_loss: 0.9133 - val_accuracy: 0.7260\n",
      "Epoch 369/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.9014 - val_loss: 0.9105 - val_accuracy: 0.7288\n",
      "Epoch 370/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8959 - val_loss: 0.9551 - val_accuracy: 0.7041\n",
      "Epoch 371/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2357 - accuracy: 0.8993 - val_loss: 0.9450 - val_accuracy: 0.7233\n",
      "Epoch 372/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.8870 - val_loss: 0.9621 - val_accuracy: 0.7123\n",
      "Epoch 373/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2503 - accuracy: 0.8884 - val_loss: 0.8965 - val_accuracy: 0.7151\n",
      "Epoch 374/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.8897 - val_loss: 0.8480 - val_accuracy: 0.7342\n",
      "Epoch 375/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9068 - val_loss: 0.8060 - val_accuracy: 0.7562\n",
      "Epoch 376/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.8952 - val_loss: 0.7673 - val_accuracy: 0.7562\n",
      "Epoch 377/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.8966 - val_loss: 0.8425 - val_accuracy: 0.7589\n",
      "Epoch 378/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.8979 - val_loss: 0.8507 - val_accuracy: 0.7452\n",
      "Epoch 379/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.8959 - val_loss: 0.8296 - val_accuracy: 0.7534\n",
      "Epoch 380/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9000 - val_loss: 0.7976 - val_accuracy: 0.7562\n",
      "Epoch 381/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9048 - val_loss: 0.8284 - val_accuracy: 0.7425\n",
      "Epoch 382/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9062 - val_loss: 0.8815 - val_accuracy: 0.7342\n",
      "Epoch 383/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9007 - val_loss: 0.7915 - val_accuracy: 0.7479\n",
      "Epoch 384/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2275 - accuracy: 0.9034 - val_loss: 0.8417 - val_accuracy: 0.7205\n",
      "Epoch 385/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2364 - accuracy: 0.8973 - val_loss: 0.8668 - val_accuracy: 0.7178\n",
      "Epoch 386/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.8973 - val_loss: 0.8945 - val_accuracy: 0.7260\n",
      "Epoch 387/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.8966 - val_loss: 0.8965 - val_accuracy: 0.7233\n",
      "Epoch 388/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9007 - val_loss: 0.9018 - val_accuracy: 0.7233\n",
      "Epoch 389/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9103 - val_loss: 0.8365 - val_accuracy: 0.7425\n",
      "Epoch 390/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.9027 - val_loss: 0.8563 - val_accuracy: 0.7205\n",
      "Epoch 391/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9130 - val_loss: 0.9285 - val_accuracy: 0.7014\n",
      "Epoch 392/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9062 - val_loss: 0.9082 - val_accuracy: 0.7315\n",
      "Epoch 393/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9082 - val_loss: 1.0127 - val_accuracy: 0.7041\n",
      "Epoch 394/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.9014 - val_loss: 0.9668 - val_accuracy: 0.7233\n",
      "Epoch 395/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.8884 - val_loss: 0.9483 - val_accuracy: 0.7151\n",
      "Epoch 396/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9068 - val_loss: 0.8706 - val_accuracy: 0.7233\n",
      "Epoch 397/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2310 - accuracy: 0.8979 - val_loss: 0.9670 - val_accuracy: 0.7096\n",
      "Epoch 398/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.9096 - val_loss: 0.8837 - val_accuracy: 0.7425\n",
      "Epoch 399/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9048 - val_loss: 0.9001 - val_accuracy: 0.7233\n",
      "Epoch 400/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9116 - val_loss: 0.9244 - val_accuracy: 0.7452\n",
      "Epoch 401/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9007 - val_loss: 0.9338 - val_accuracy: 0.7342\n",
      "Epoch 402/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9075 - val_loss: 0.8315 - val_accuracy: 0.7562\n",
      "Epoch 403/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.8938 - val_loss: 0.9631 - val_accuracy: 0.7479\n",
      "Epoch 404/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9082 - val_loss: 1.0114 - val_accuracy: 0.7068\n",
      "Epoch 405/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9027 - val_loss: 0.9077 - val_accuracy: 0.7534\n",
      "Epoch 406/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2119 - accuracy: 0.9089 - val_loss: 1.0139 - val_accuracy: 0.7123\n",
      "Epoch 407/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9110 - val_loss: 0.9758 - val_accuracy: 0.7123\n",
      "Epoch 408/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2180 - accuracy: 0.9068 - val_loss: 0.9039 - val_accuracy: 0.7479\n",
      "Epoch 409/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.8877 - val_loss: 0.9441 - val_accuracy: 0.7288\n",
      "Epoch 410/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.9110 - val_loss: 1.0603 - val_accuracy: 0.7041\n",
      "Epoch 411/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9171 - val_loss: 0.9302 - val_accuracy: 0.7315\n",
      "Epoch 412/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9062 - val_loss: 0.9665 - val_accuracy: 0.7014\n",
      "Epoch 413/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9082 - val_loss: 0.8994 - val_accuracy: 0.7205\n",
      "Epoch 414/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.9116 - val_loss: 0.9670 - val_accuracy: 0.7151\n",
      "Epoch 415/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.9021 - val_loss: 0.8600 - val_accuracy: 0.7425\n",
      "Epoch 416/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2099 - accuracy: 0.9116 - val_loss: 0.9789 - val_accuracy: 0.7233\n",
      "Epoch 417/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.8986 - val_loss: 0.9065 - val_accuracy: 0.7342\n",
      "Epoch 418/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9055 - val_loss: 0.9559 - val_accuracy: 0.7315\n",
      "Epoch 419/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9089 - val_loss: 0.9795 - val_accuracy: 0.7370\n",
      "Epoch 420/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.9137 - val_loss: 0.9595 - val_accuracy: 0.7315\n",
      "Epoch 421/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.9103 - val_loss: 1.0022 - val_accuracy: 0.7151\n",
      "Epoch 422/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9048 - val_loss: 1.0338 - val_accuracy: 0.7123\n",
      "Epoch 423/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.9178 - val_loss: 1.1351 - val_accuracy: 0.7068\n",
      "Epoch 424/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.9205 - val_loss: 1.0034 - val_accuracy: 0.7041\n",
      "Epoch 425/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9123 - val_loss: 0.9714 - val_accuracy: 0.7315\n",
      "Epoch 426/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.9144 - val_loss: 0.9587 - val_accuracy: 0.7233\n",
      "Epoch 427/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9185 - val_loss: 1.0436 - val_accuracy: 0.7288\n",
      "Epoch 428/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.9130 - val_loss: 1.0008 - val_accuracy: 0.7260\n",
      "Epoch 429/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.9130 - val_loss: 0.9818 - val_accuracy: 0.7288\n",
      "Epoch 430/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2232 - accuracy: 0.8932 - val_loss: 0.9984 - val_accuracy: 0.7342\n",
      "Epoch 431/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9062 - val_loss: 1.0073 - val_accuracy: 0.7151\n",
      "Epoch 432/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.9178 - val_loss: 0.9143 - val_accuracy: 0.7452\n",
      "Epoch 433/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.9158 - val_loss: 0.9373 - val_accuracy: 0.7370\n",
      "Epoch 434/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9116 - val_loss: 1.0326 - val_accuracy: 0.7288\n",
      "Epoch 435/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9144 - val_loss: 1.1105 - val_accuracy: 0.6822\n",
      "Epoch 436/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.9089 - val_loss: 1.0290 - val_accuracy: 0.7068\n",
      "Epoch 437/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.9178 - val_loss: 1.0536 - val_accuracy: 0.6932\n",
      "Epoch 438/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.8966 - val_loss: 0.9479 - val_accuracy: 0.7452\n",
      "Epoch 439/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9089 - val_loss: 1.0118 - val_accuracy: 0.7123\n",
      "Epoch 440/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.9082 - val_loss: 0.9501 - val_accuracy: 0.7397\n",
      "Epoch 441/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9123 - val_loss: 1.0288 - val_accuracy: 0.7205\n",
      "Epoch 442/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9062 - val_loss: 0.9944 - val_accuracy: 0.7233\n",
      "Epoch 443/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.9144 - val_loss: 1.0528 - val_accuracy: 0.7288\n",
      "Epoch 444/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9123 - val_loss: 1.1200 - val_accuracy: 0.6877\n",
      "Epoch 445/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2048 - accuracy: 0.9089 - val_loss: 0.9575 - val_accuracy: 0.7452\n",
      "Epoch 446/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9185 - val_loss: 0.9496 - val_accuracy: 0.7425\n",
      "Epoch 447/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.9219 - val_loss: 1.0201 - val_accuracy: 0.7123\n",
      "Epoch 448/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.9178 - val_loss: 1.1642 - val_accuracy: 0.6877\n",
      "Epoch 449/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.9178 - val_loss: 1.0017 - val_accuracy: 0.7370\n",
      "Epoch 450/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.9103 - val_loss: 1.0593 - val_accuracy: 0.7288\n",
      "Epoch 451/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.9068 - val_loss: 1.0546 - val_accuracy: 0.7041\n",
      "Epoch 452/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.9226 - val_loss: 0.9414 - val_accuracy: 0.7260\n",
      "Epoch 453/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9199 - val_loss: 0.9325 - val_accuracy: 0.7370\n",
      "Epoch 454/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9226 - val_loss: 1.1032 - val_accuracy: 0.6959\n",
      "Epoch 455/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9171 - val_loss: 1.0317 - val_accuracy: 0.7315\n",
      "Epoch 456/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9199 - val_loss: 1.1413 - val_accuracy: 0.7233\n",
      "Epoch 457/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.9055 - val_loss: 1.0471 - val_accuracy: 0.7123\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.9123 - val_loss: 1.0861 - val_accuracy: 0.7205\n",
      "Epoch 459/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.9212 - val_loss: 1.0984 - val_accuracy: 0.6740\n",
      "Epoch 460/500\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9144 - val_loss: 1.0146 - val_accuracy: 0.7342\n",
      "Epoch 461/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9130 - val_loss: 0.9779 - val_accuracy: 0.7370\n",
      "Epoch 462/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9205 - val_loss: 1.1384 - val_accuracy: 0.7151\n",
      "Epoch 463/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.9185 - val_loss: 0.9914 - val_accuracy: 0.7370\n",
      "Epoch 464/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.9199 - val_loss: 1.0658 - val_accuracy: 0.7370\n",
      "Epoch 465/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.9281 - val_loss: 1.0349 - val_accuracy: 0.7288\n",
      "Epoch 466/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9185 - val_loss: 1.0466 - val_accuracy: 0.7096\n",
      "Epoch 467/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.9164 - val_loss: 1.1448 - val_accuracy: 0.7096\n",
      "Epoch 468/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9219 - val_loss: 1.1036 - val_accuracy: 0.7397\n",
      "Epoch 469/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9110 - val_loss: 1.0032 - val_accuracy: 0.7315\n",
      "Epoch 470/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.9144 - val_loss: 1.0518 - val_accuracy: 0.7397\n",
      "Epoch 471/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.9219 - val_loss: 1.0962 - val_accuracy: 0.7315\n",
      "Epoch 472/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9158 - val_loss: 1.0540 - val_accuracy: 0.7233\n",
      "Epoch 473/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9260 - val_loss: 1.0313 - val_accuracy: 0.7260\n",
      "Epoch 474/500\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.90 - 0s 1ms/step - loss: 0.2086 - accuracy: 0.9068 - val_loss: 1.1625 - val_accuracy: 0.7041\n",
      "Epoch 475/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9151 - val_loss: 1.1622 - val_accuracy: 0.7151\n",
      "Epoch 476/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9110 - val_loss: 1.2794 - val_accuracy: 0.6822\n",
      "Epoch 477/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.9089 - val_loss: 1.1310 - val_accuracy: 0.7096\n",
      "Epoch 478/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9219 - val_loss: 1.1162 - val_accuracy: 0.7452\n",
      "Epoch 479/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9116 - val_loss: 1.1676 - val_accuracy: 0.7178\n",
      "Epoch 480/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9226 - val_loss: 1.0715 - val_accuracy: 0.7178\n",
      "Epoch 481/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9219 - val_loss: 1.1898 - val_accuracy: 0.7151\n",
      "Epoch 482/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1714 - accuracy: 0.9322 - val_loss: 1.1957 - val_accuracy: 0.7205\n",
      "Epoch 483/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.9137 - val_loss: 1.2454 - val_accuracy: 0.7096\n",
      "Epoch 484/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.9171 - val_loss: 1.1453 - val_accuracy: 0.6904\n",
      "Epoch 485/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9308 - val_loss: 1.0797 - val_accuracy: 0.7342\n",
      "Epoch 486/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1741 - accuracy: 0.9349 - val_loss: 1.2327 - val_accuracy: 0.7041\n",
      "Epoch 487/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.9219 - val_loss: 1.2337 - val_accuracy: 0.6877\n",
      "Epoch 488/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.9199 - val_loss: 1.1090 - val_accuracy: 0.7123\n",
      "Epoch 489/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.9151 - val_loss: 1.2504 - val_accuracy: 0.7260\n",
      "Epoch 490/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.9205 - val_loss: 1.0828 - val_accuracy: 0.7205\n",
      "Epoch 491/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9295 - val_loss: 1.1259 - val_accuracy: 0.7233\n",
      "Epoch 492/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9336 - val_loss: 1.0721 - val_accuracy: 0.7397\n",
      "Epoch 493/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.9267 - val_loss: 1.3018 - val_accuracy: 0.6932\n",
      "Epoch 494/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9315 - val_loss: 1.1118 - val_accuracy: 0.7068\n",
      "Epoch 495/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9226 - val_loss: 1.3070 - val_accuracy: 0.6932\n",
      "Epoch 496/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9171 - val_loss: 1.1795 - val_accuracy: 0.7014\n",
      "Epoch 497/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.9212 - val_loss: 1.2385 - val_accuracy: 0.7068\n",
      "Epoch 498/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.9219 - val_loss: 1.1107 - val_accuracy: 0.7151\n",
      "Epoch 499/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.9260 - val_loss: 1.0548 - val_accuracy: 0.7288\n",
      "Epoch 500/500\n",
      "46/46 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.9096 - val_loss: 1.1735 - val_accuracy: 0.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6f0b22e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.Input(shape=(144,)))\n",
    "ann.add(tf.keras.layers.Dense(units = 90, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units = 30, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units= 1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ann.fit(X_train_ann, y_train_ann, batch_size=32, epochs=500, verbose=1, validation_data=(X_test_ann, y_test_ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7875519046759343\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test_ann)\n",
    "auc = roc_auc_score(y_test_ann, y_pred)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN + LSTM + embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM (24h) + ANN (media delle features nel giorno precedente) + embedding sul mese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>pollution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-5.125000</td>\n",
       "      <td>1024.750000</td>\n",
       "      <td>24.860000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>-10.125000</td>\n",
       "      <td>-8.541667</td>\n",
       "      <td>1022.791667</td>\n",
       "      <td>70.937917</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>-20.875000</td>\n",
       "      <td>-11.500000</td>\n",
       "      <td>1029.291667</td>\n",
       "      <td>111.160833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>-24.583333</td>\n",
       "      <td>-14.458333</td>\n",
       "      <td>1033.625000</td>\n",
       "      <td>56.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-23.708333</td>\n",
       "      <td>-12.541667</td>\n",
       "      <td>1033.750000</td>\n",
       "      <td>18.511667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dew       temp        press     wnd_spd       snow  rain  \\\n",
       "timestamp                                                                    \n",
       "2010-01-02  -8.500000  -5.125000  1024.750000   24.860000   0.708333   0.0   \n",
       "2010-01-03 -10.125000  -8.541667  1022.791667   70.937917  14.166667   0.0   \n",
       "2010-01-04 -20.875000 -11.500000  1029.291667  111.160833   0.000000   0.0   \n",
       "2010-01-05 -24.583333 -14.458333  1033.625000   56.920000   0.000000   0.0   \n",
       "2010-01-06 -23.708333 -12.541667  1033.750000   18.511667   0.000000   0.0   \n",
       "\n",
       "            pollution  \n",
       "timestamp              \n",
       "2010-01-02        1.0  \n",
       "2010-01-03        0.0  \n",
       "2010-01-04        0.0  \n",
       "2010-01-05        0.0  \n",
       "2010-01-06        0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prev = df\n",
    "df_prev.drop(['hour'], axis=1, inplace=True)\n",
    "df_prev = df.groupby('timestamp').mean()\n",
    "df_prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "      <th>pollution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>1.828516</td>\n",
       "      <td>12.459041</td>\n",
       "      <td>1016.447306</td>\n",
       "      <td>23.894307</td>\n",
       "      <td>0.052763</td>\n",
       "      <td>0.195023</td>\n",
       "      <td>0.481096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>-8.500000</td>\n",
       "      <td>-5.125000</td>\n",
       "      <td>1024.750000</td>\n",
       "      <td>24.860000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>-10.125000</td>\n",
       "      <td>-8.541667</td>\n",
       "      <td>1022.791667</td>\n",
       "      <td>70.937917</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>-20.875000</td>\n",
       "      <td>-11.500000</td>\n",
       "      <td>1029.291667</td>\n",
       "      <td>111.160833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>-24.583333</td>\n",
       "      <td>-14.458333</td>\n",
       "      <td>1033.625000</td>\n",
       "      <td>56.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dew       temp        press     wnd_spd       snow  \\\n",
       "2010-01-01   1.828516  12.459041  1016.447306   23.894307   0.052763   \n",
       "2010-01-02  -8.500000  -5.125000  1024.750000   24.860000   0.708333   \n",
       "2010-01-03 -10.125000  -8.541667  1022.791667   70.937917  14.166667   \n",
       "2010-01-04 -20.875000 -11.500000  1029.291667  111.160833   0.000000   \n",
       "2010-01-05 -24.583333 -14.458333  1033.625000   56.920000   0.000000   \n",
       "\n",
       "                rain  pollution  \n",
       "2010-01-01  0.195023   0.481096  \n",
       "2010-01-02  0.000000   1.000000  \n",
       "2010-01-03  0.000000   0.000000  \n",
       "2010-01-04  0.000000   0.000000  \n",
       "2010-01-05  0.000000   0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame({'dew': df['dew'].mean(), \n",
    "                    'temp': df['temp'].mean(), \n",
    "                    'press': df['press'].mean(),\n",
    "                    'wnd_spd': df['wnd_spd'].mean(),\n",
    "                    'snow': df['snow'].mean(),\n",
    "                    'rain': df['rain'].mean(),\n",
    "                    'pollution': df['pollution'].mean()}, index=['2010-01-01'])\n",
    "#df_prev = pd.concat([df_0.head(), df_prev], axis=0)\n",
    "df_prev = pd.concat([df_0, df_prev], axis=0)\n",
    "df_prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_prev.index) * 0.8)\n",
    "X_train_ann = df_prev.iloc[:train_size, :]\n",
    "X_test_ann = df_prev.iloc[train_size:-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added embedding layer on the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           month\n",
       "2010-01-01    01\n",
       "2010-01-02    01\n",
       "2010-01-03    01\n",
       "2010-01-04    01\n",
       "2010-01-05    01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day = pd.DataFrame(df_prev.index, columns=['month'])\n",
    "df_day.index = df_prev.index\n",
    "df_day['month'] = pd.to_datetime(df_day[\"month\"])\n",
    "df_day['month'] = df_day.month.dt.strftime('%m')\n",
    "df_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-03</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-27</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-28</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-29</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-30</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1826 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            month_int\n",
       "2010-01-01          1\n",
       "2010-01-02          1\n",
       "2010-01-03          1\n",
       "2010-01-04          1\n",
       "2010-01-05          1\n",
       "...               ...\n",
       "2014-12-27         12\n",
       "2014-12-28         12\n",
       "2014-12-29         12\n",
       "2014-12-30         12\n",
       "2014-12-31         12\n",
       "\n",
       "[1826 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day['month_int'] = df_day['month'].astype('int32')\n",
    "df_day.drop('month', axis=1, inplace=True)\n",
    "df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df_day.index) * 0.8)\n",
    "X_train_emb = df_day.iloc[:train_size, :]\n",
    "X_test_emb = df_day.iloc[train_size:-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 4s 19ms/step - loss: 106.1331 - auc: 0.5000\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 40.7637 - auc: 0.5000\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 3.5378 - auc: 0.5461\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.7016 - auc: 0.6736\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6744 - auc: 0.6888\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6798 - auc: 0.6686\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.6597 - auc: 0.6901\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6476 - auc: 0.6916\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6609 - auc: 0.6664\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6406 - auc: 0.6919\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.6407 - auc: 0.6905\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6403 - auc: 0.6865\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6347 - auc: 0.6979\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6378 - auc: 0.6908\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6591 - auc: 0.6671\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6446 - auc: 0.6818\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6475 - auc: 0.6730\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6356 - auc: 0.6991\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6403 - auc: 0.6821\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6326 - auc: 0.7004\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6376 - auc: 0.6852\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.6292 - auc: 0.7041\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6328 - auc: 0.6982\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6360 - auc: 0.6869\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 1s 20ms/step - loss: 0.6326 - auc: 0.6936\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 1s 19ms/step - loss: 0.6341 - auc: 0.6911\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6575 - auc: 0.6713\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6416 - auc: 0.6843\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6398 - auc: 0.6834\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6477 - auc: 0.6722\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6254 - auc: 0.7143\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6277 - auc: 0.7026\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6278 - auc: 0.7060\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6295 - auc: 0.7041\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6181 - auc: 0.7186\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6204 - auc: 0.7129\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6393 - auc: 0.6806\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6255 - auc: 0.7015\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6199 - auc: 0.7160\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6267 - auc: 0.6985\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6372 - auc: 0.6862\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6414 - auc: 0.6827\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6183 - auc: 0.7147\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6304 - auc: 0.6984\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6236 - auc: 0.7134\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6461 - auc: 0.6722\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6252 - auc: 0.6998\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6338 - auc: 0.6933\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6218 - auc: 0.7076\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6382 - auc: 0.6914\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6255 - auc: 0.7001\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6320 - auc: 0.6941\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6279 - auc: 0.6992\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6247 - auc: 0.7002\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6293 - auc: 0.6967\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6416 - auc: 0.6839\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6321 - auc: 0.6890\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6288 - auc: 0.6962\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6148 - auc: 0.7163\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6480 - auc: 0.6896\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6403 - auc: 0.6921\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6337 - auc: 0.6971\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6243 - auc: 0.7053\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6323 - auc: 0.6958\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6242 - auc: 0.6962\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6321 - auc: 0.6921\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6323 - auc: 0.7008\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6468 - auc: 0.6844\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6108 - auc: 0.7227\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6201 - auc: 0.7067\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6179 - auc: 0.7104\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6205 - auc: 0.7084\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6220 - auc: 0.7020\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6182 - auc: 0.7110\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6093 - auc: 0.7239\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6148 - auc: 0.7113\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6132 - auc: 0.7165\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6486 - auc: 0.6770\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6305 - auc: 0.6901\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6111 - auc: 0.7209\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6090 - auc: 0.7285\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6079 - auc: 0.7270\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 0.6244 - auc: 0.6986\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.6176 - auc: 0.7093\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6130 - auc: 0.7165\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6076 - auc: 0.7238\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6164 - auc: 0.7118\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6035 - auc: 0.7319\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6479 - auc: 0.6818\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6301 - auc: 0.6998\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.6013 - auc: 0.7343\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6070 - auc: 0.7270\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.5945 - auc: 0.7425\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6240 - auc: 0.7071\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6413 - auc: 0.6946\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6157 - auc: 0.7205\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 0.6100 - auc: 0.7237\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 0.5874 - auc: 0.7461\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.5702 - auc: 0.7643\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 1s 25ms/step - loss: 0.5442 - auc: 0.7959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6f120fd90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "\n",
    "first_input = Input(shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
    "rnn_layer1 = LSTM(units=100, return_sequences=True)(first_input)\n",
    "rnn_layer2 = LSTM(units=100, return_sequences=False)(rnn_layer1)\n",
    "rnn_layer3 = Dense(20, activation='relu')(rnn_layer2)\n",
    "\n",
    "second_input = Input(shape=(X_train_ann.shape[1], ))\n",
    "ann_layer1 = Dense(5, activation='relu')(second_input)\n",
    "\n",
    "third_input = Input(shape=(1,1))\n",
    "emb_layer1 = Embedding(13, 1)(third_input)\n",
    "emb_layer2 = Flatten()(emb_layer1)\n",
    "\n",
    "merged = concatenate([rnn_layer3, ann_layer1, emb_layer2])\n",
    "dense = Dense(10, activation='relu')(merged)\n",
    "output = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = Model(inputs=[first_input, second_input, third_input], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "model.fit([X_train_lstm, X_train_ann, X_train_emb], y_train_lstm, epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7115303604742131\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred = model.predict([X_test_lstm, X_test_ann, X_test_emb])\n",
    "auc = roc_auc_score(y_test_lstm, y_pred)\n",
    "print('AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.046547  ],\n",
      "       [ 0.01539929],\n",
      "       [ 0.2521121 ],\n",
      "       [ 0.10881738],\n",
      "       [ 0.14236435],\n",
      "       [ 0.14570846],\n",
      "       [ 0.26986825],\n",
      "       [-0.3041248 ],\n",
      "       [-0.63447654],\n",
      "       [-0.69903916],\n",
      "       [-0.49912006],\n",
      "       [ 0.05343078],\n",
      "       [ 0.05170352]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if 'Embedding' in str(layer):\n",
    "        print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
